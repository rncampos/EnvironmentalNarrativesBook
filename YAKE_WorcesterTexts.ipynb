{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<b><center><font size=\"4\">Greening a PostIndustrial City:  Applying keyword extractor methods to monitor a fast-changing environmental narrative</font></center></b>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Notebook developed by: [Ricardo Campos](http://www.ccc.ipt.pt/~ricardo) in the scope of chapter X (written by [Sarah Luria](https://www.holycross.edu/academics/programs/english/faculty/sarah-luria) and [Ricardo Campos](http://www.ccc.ipt.pt/~ricardo)) of the Environmental Narratives book.\n",
    "<br>\n",
    "\n",
    "<p><a href=\"https://github.com/rncampos/EnvironmentalNarrativesBook/blob/master/YAKE_WorcesterTexts.ipynb\" title=\"Download Notebook\" download><img src=\"../images/download.jpg\" align = \"left\" width=\"50\" height=\"50\" alt=\"Download Notebook\"></a></p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Pre-Processing\" data-toc-modified-id=\"Pre-Processing-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Pre-Processing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Image-Files\" data-toc-modified-id=\"Image-Files-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Image Files</a></span><ul class=\"toc-item\"><li><span><a href=\"#Optical-Character-Recognition-(OCR)\" data-toc-modified-id=\"Optical-Character-Recognition-(OCR)-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Optical Character Recognition (OCR)</a></span></li><li><span><a href=\"#Tesseract\" data-toc-modified-id=\"Tesseract-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Tesseract</a></span></li><li><span><a href=\"#pytesseract\" data-toc-modified-id=\"pytesseract-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>pytesseract</a></span></li></ul></li><li><span><a href=\"#PDF-Files\" data-toc-modified-id=\"PDF-Files-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>PDF Files</a></span><ul class=\"toc-item\"><li><span><a href=\"#Plain-Text\" data-toc-modified-id=\"Plain-Text-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Plain Text</a></span></li><li><span><a href=\"#non-plain-text\" data-toc-modified-id=\"non-plain-text-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>non-plain text</a></span><ul class=\"toc-item\"><li><span><a href=\"#ConvertPdf2Images\" data-toc-modified-id=\"ConvertPdf2Images-1.2.2.1\"><span class=\"toc-item-num\">1.2.2.1&nbsp;&nbsp;</span>ConvertPdf2Images</a></span></li><li><span><a href=\"#pytesseract\" data-toc-modified-id=\"pytesseract-1.2.2.2\"><span class=\"toc-item-num\">1.2.2.2&nbsp;&nbsp;</span>pytesseract</a></span></li></ul></li></ul></li><li><span><a href=\"#MS-Word-Files\" data-toc-modified-id=\"MS-Word-Files-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>MS Word Files</a></span></li></ul></li><li><span><a href=\"#Information-Extraction\" data-toc-modified-id=\"Information-Extraction-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Information Extraction</a></span><ul class=\"toc-item\"><li><span><a href=\"#YAKE!\" data-toc-modified-id=\"YAKE!-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>YAKE!</a></span><ul class=\"toc-item\"><li><span><a href=\"#Running-YAKE!\" data-toc-modified-id=\"Running-YAKE!-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Running YAKE!</a></span></li><li><span><a href=\"#Awards\" data-toc-modified-id=\"Awards-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Awards</a></span></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>References</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this collaboration, literary geographer [Sarah Luria](https://www.holycross.edu/academics/programs/english/faculty/sarah-luria) teams up with computer scientist [Ricardo Campos](http://www.ccc.ipt.pt/~ricardo), developer of the keyword extractor [YAKE!](http://yake.inesctec.pt) to discover if it can create a helpful survey or image of stories told about a neighborhood over time. Our aim is to show how Artificial Intelligence can track the fast changing story local development and environmental cleanup. Most importantly, we hope that by being able to process a range of documents and sources, a more democratic, representative, picture of public discourse might be produced.  \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we show the procedure (and the code) used to extract text embedded in images, pdfs and ms word files. \n",
    "Note that this code is made available only for illustrative purposes and to be used in the future by other researchers interested in obtaining texts from similar document files, as the curated pre-processing texts are already available to play with. So if your interest is only in replicating our experiments, go directly to the section \"Information Extraction\", to run YAKE! on top of pre-processed already available files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In any case begin by downloading the set of texts [here](https://github.com/rncampos/EnvironmentalNarrativesBook/blob/master/Dataset.zip)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After unziping the file you should end up with the following structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----data\n",
    "<br>\n",
    "--------Texts\n",
    "    <br>\n",
    "------------1_Images\n",
    "        <br>\n",
    "------------2_Pdfs_with_images\n",
    "        <br>\n",
    "------------3_Pdfs\n",
    "        <br>\n",
    "------------4_MSWord\n",
    "        <br>\n",
    "------------5_AllTextsCurated<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that as previously referred, the folders `1_Images`, `2_Pdfs_with_images`, `3_Pdfs` and `4_MSWord` contain (for illustrative purposes) the files to be processed. In case you are only interested in replicating our experiments, go directly to the section \"Information Extraction\", where we explain how to run YAKE! on top of all the pre-processed curated files (which you can find in the `5_AllTextsCurated` folder)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optical Character Recognition (OCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading texts from image files implies aplying an `Optical Character Recognition (OCR)` mechanism, a machine learning technique used to transform images containing analog-born text (e.g., old scanned texts) into text itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract text from images we use `tesseract`, an open source text recognition engine (OCR) available under the Apache 2.0 license. It can be used directly from the command line or through programming languages using a wrapper to extract texts from images. `tesseract` supports a wide range of languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executables for Windows are available [here](https://github.com/UB-Mannheim/tesseract/wiki). To install on top of other operating systems consult this [page](https://github.com/tesseract-ocr/tesseract/wiki)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default installation includes training data for English. If you would like to apply it on top of other language, please consider downloading the corresponding [training data](https://github.com/tesseract-ocr/tesseract/wiki/Data-Files). Afterwards, unzip the file and copy the `.traineddata file `to the` tessdata` directory, likely available under this directory: `C: \\ Program Files \\ Tesseract-OCR \\ tessdata`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access `tesseract-OCR` from any location, add the installation directory (e.g., `C:\\Program Files\\Tesseract-OCR`) to the environment variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.ccc.ipt.pt/~ricardo/images/tesseract.jpg\" width=\"800\" height=\"800\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The system is now able to get texts from images through the command line. In case you want to test it, please run the following code in the prompt: `tesseract ImageFileName.jpg out`. You will notice that the obtained result will be saved in an `out` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of running the code in the command line, we recommend to use tesseract directly from this Python notebook. In the following text blocks we explain how to do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pytesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen earlier `Tesseract` is software that can be run from the command line, with support for C/C++ languages. To use it in Python you need to use a wrapper named `pytesseract`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the advantages of this library is the possibility to work with PIL (Python Image Library) type arguments, which allows tackling `jpeg`, `png`, `gif`, `bmp` or `tiff` formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract text from images in Python we use `PIL` (Python Imaging Library) and `pytesseract`. To install these libraries proceed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pillow\n",
    "!pip install pytesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code enables to import the libraries. Don't forget to define the path of tesseract installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = 'C:/Program Files/Tesseract-OCR/tesseract'\n",
    "tessdata_dir_config = r'--tessdata-dir \"C:/Program Files/Tesseract-OCR/tesseract\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the path where our images are saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/Texts/1_Images/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code iterate over each image and applies `pytesseract` to extract the corresponding text. Each txt file is then saved in the same folder, that is, in the path above defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "imageFileFormat = \"png\"\n",
    "\n",
    "ListOfTexts = []\n",
    "listFile = glob.glob(path + '*.' + imageFileFormat)\n",
    "\n",
    "for file in listFile:\n",
    "    text = pytesseract.image_to_string(Image.open(path + os.path.basename(file)))\n",
    "    f = open(path + os.path.basename(file)[:-4] + '.txt', 'w') # open in write mode. Se não existir cria o ficheiro\n",
    "    f.write(text) # write some text\n",
    "    f.close() # closes the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will explain how to extract `plain text` and` non-plain text` from PDF files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plain Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDF files are currently one of the most used file types. The vast majority of these documents were digitally-born (e.g., created from document processors such as MS Word) and as such contain plain text. A simple way to check this is to use the text selection feature on top of pdf files and see if we can select the text. If that is the case, you can concluded that the text is actually embedded in the pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction of embedded text from PDFs is possible using a number of currently available libraries. One such library is `PyPDF2`. Examples of using this library are available [here](http://www.blog.pythonlibrary.org/2018/06/07/an-intro-to-pypdf2/). In order to use `pypdf2` please proceed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pypdf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, begin be defining the path where the PDFs with palin text can be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/Texts/3_Pdfs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, execute the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import PyPDF2\n",
    "ListOfTexts = []\n",
    "listFile = glob.glob(path + '*.pdf')\n",
    "\n",
    "for file in listFile:\n",
    "    pdfFileObject = open(file, 'rb')\n",
    "    pdfReader = PyPDF2.PdfFileReader(pdfFileObject)\n",
    "    count = pdfReader.numPages\n",
    "    PageContent = []\n",
    "    for i in range(count):\n",
    "        page = pdfReader.getPage(i)\n",
    "        content = page.extractText()\n",
    "        PageContent.append(content.encode('utf-8'))\n",
    "        for page in PageContent:\n",
    "            f = open(file[:-4] + \".txt\", 'wb') # open in write mode. Se não existir cria o ficheiro\n",
    "            for content in PageContent:\n",
    "                f.write(content) # write some text\n",
    "            f.close() # closes the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### non-plain text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract text not embedded in a pdf we have to use the OCR (Optical Character Recognition) mechanism, namely `Tesseract` an  open-source text recognition system commonly used to extract text from images (e.g., digitized texts). However, since `Tesseract` cannot work directly on top of PDFs, we will first have to convert the pdf to images. Extracting non-embedded PDF text therefore requires two tasks:\n",
    "- convert the PDF to images;\n",
    "- use OCR to extract text from images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ConvertPdf2Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it may contain images, a PDF is not an image itself and therefore we cannot directly OCR it. To convert PDFs to images, we use `ImageMagick's` conversion function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install `ImageMagick` on Windows operating system, go to the following page: http://www.imagemagick.org/download/binaries/ and download the executable` ImageMagick-6.9.10-55-Q8-x64-dll`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, install `wand` a wrapper of ImageMagick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wand==0.4.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the following environment variable:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.ccc.ipt.pt/~ricardo/images/magic.jpg\" width=\"800\" height=\"800\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to install ImageMagick on another operating system, refer to the instructions on the following page: http://docs.wand-py.org/en/latest/guide/install.html#install-imagemagick-on-windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pytesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the software installed, we can resort to pytesseract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we begin by defining the path where our pdfs with images are saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/Texts/2_Pdfs_with_images/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then convert the pdf to the images (as many images as the number of pages in the pdf). Following, we extract the text from each image and join it into a single file (one text per each pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from wand.image import Image as Img\n",
    "\n",
    "imageFileFormat = \"png\"\n",
    "\n",
    "ListOfTexts = []\n",
    "listFile = glob.glob(path + '*.pdf')\n",
    "\n",
    "for file in listFile:\n",
    "    with Img(filename=file, resolution=300) as img:\n",
    "        img.compression_quality = 99\n",
    "        img.save(filename=path + os.path.basename(file)[:-4] + \".\" + imageFileFormat)\n",
    "    \n",
    "    #Obter a lista de pngs gerados (tantos quantos o número de páginas existentes no pdf)\n",
    "    listOfPNGFiles = glob.glob(path + os.path.basename(file)[:-4] + '*.' + imageFileFormat)\n",
    "    text = \"\"\n",
    "    for pictureFile in listOfPNGFiles:\n",
    "        text += pytesseract.image_to_string(Image.open(path + os.path.basename(pictureFile)))\n",
    "\n",
    "    f = open(path + os.path.basename(file)[:-4] + '.txt', 'w') # open in write mode. Se não existir cria o ficheiro\n",
    "    f.write(text) # write some text\n",
    "    f.close() # closes the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MS Word Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract text from Word docs we will use `TIKA` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tika"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define the path where the MS words files can be found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/Texts/4_MSWord/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from tika import parser\n",
    "\n",
    "ListOfTexts = []\n",
    "listFile = glob.glob(path + '*.docx')\n",
    "for file in listFile:\n",
    "    parsed = parser.from_file(file)\n",
    "    f = open(file[:-4] + \"txt\", 'w', encoding=\"utf8\") # open in write mode. Se não existir cria o ficheiro\n",
    "    f.write(parsed[\"content\"]) # write some text\n",
    "    f.close() # closes the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YAKE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div align=\"center\"><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/LB5UV0cbDm8\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<div align=\"center\"><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/LB5UV0cbDm8\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe></div>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YAKE! is a light-weight unsupervised automatic keyword extraction method which rests on text statistical features extracted from single documents to select the most important keywords of a text. YAKE! does not need to be trained on a particular set of documents, neither it depends on dictionaries, external-corpus, size of the text, language or domain. Its available through a python [package](https://github.com/LIAAD/yake), a [demo](http://yake.inesctec.pt), an [API](http://yake.inesctec.pt/apidocs/#!/available_methods/post_yake_v2_extract_keywords) and a [mobile app](https://play.google.com/store/apps/details?id=com.yake.yake)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running YAKE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this work, we are going to run YAKE! on top of the pre-processed curated texts which can be found in the folder `5_AllTextsCurated`. By running the following code, we get, for each text, five lists of the top-40 relevant keywords. The first list consists of keywords formed by single terms (1-gram), the second by keywords consisting of keyhrases up to 2-terms (2-gram), the third up to 3-terms, the fourth up to 5-terms and the final one up to 10-terms. The list of relevant keywords  are saved in an html file (one per text file). The idea here is to give the reader the chance to choose the number of terms that best fits his/her understanding of the text. However, the experiments conducted, show that most effective results occur when n is set to 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to this, the code also produces, for each text, a wordcloud of the most relevant keywords (here n is only set to n = 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the following code, we suggest to creat this structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----data\n",
    "<br>\n",
    "--------Texts_Keywords\n",
    "<br>\n",
    "--------WordClouds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can access the final results (keywords + wordclouds) by downloading the results [file](https://github.com/rncampos/EnvironmentalNarrativesBook/blob/master/Results.zip)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathTextsKeywords = \"data/Texts_Keywords/\"\n",
    "pathWordCloud = \"data/WordClouds/\"\n",
    "pathTxt = \"data/Texts/5_AllTextsCurated/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import yake\n",
    "import os\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', None, 'display.max_colwidth', -1)\n",
    "\n",
    "ngrams = [1, 2, 3, 5, 10]\n",
    "\n",
    "listFile = glob.glob(pathTxt + '*.txt')\n",
    "\n",
    "for filePath in listFile:\n",
    "    print(os.path.basename(filePath)[:-4])\n",
    "    file = open(filePath)\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    \n",
    "    ListOfYAKEKeywords = []\n",
    "    ListOfYAKEKeywords_lim = []\n",
    "    for gram in ngrams:\n",
    "        custom_kwextractor = yake.KeywordExtractor(lan=\"en\", n=gram, dedupLim=0.5, top=40)\n",
    "        keywords = custom_kwextractor.extract_keywords(text)\n",
    "        kw = [keyword[0] for keyword in keywords]\n",
    "        ListOfYAKEKeywords.append(kw)\n",
    "        \n",
    "        #Generate Word Cloud for YAKE when n = 3\n",
    "        if gram == 3:\n",
    "            freqs = {key[0]: 1 - key[1] for key in keywords}\n",
    "            wordcloud = WordCloud(background_color=\"white\", max_font_size=100,width = 800, height = 600) #Objeto que permite gerar wordcloud a partir de texto\n",
    "            wordcloud.generate_from_frequencies(freqs)\n",
    "            plt.figure(figsize=(16,9))\n",
    "        \n",
    "            # store to file\n",
    "            wordcloud.to_file(pathWordCloud + os.path.basename(filePath)[:-4] + \".jpg\")\n",
    "          \n",
    "    #zip para que cada linha fique com os respetivos valores dos items considerados\n",
    "    dataYAKE = list(zip(ListOfYAKEKeywords[0], ListOfYAKEKeywords[1], ListOfYAKEKeywords[2], ListOfYAKEKeywords[3], ListOfYAKEKeywords[4]))\n",
    "              \n",
    "    #gerar o dataframe yake\n",
    "    df1 = pd.DataFrame(dataYAKE)\n",
    "    df1.columns = ['n = 1', 'n = 2', 'n = 3', 'n = 5', 'n = 10']\n",
    "    df1.index = range(1, len(dataYAKE) + 1)\n",
    "    \n",
    "    #guardar os resultados do dataframe yake num ficheiro .html\n",
    "    html = df1.to_html()\n",
    "    with open(pathTextsKeywords + os.path.basename(filePath)[:-4] + \"_YAKE_Keywords\" + \".html\", \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Awards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ECIR'18](http://ecir2018.org) Best Short Paper (see the below reference)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please cite the following works when using YAKE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** In-depth journal paper at Information Sciences Journal **\n",
    "\n",
    "Campos, R., Mangaravite, V., Pasquali, A., Jatowt, A., Jorge, A., Nunes, C. and Jatowt, A. (2020). YAKE! Keyword Extraction from Single Documents using Multiple Local Features. In Information Sciences Journal. Elsevier, Vol 509, pp 257-289. [pdf](https://doi.org/10.1016/j.ins.2019.09.013)\n",
    "\n",
    "** ECIR'18 Best Short Paper **\n",
    "\n",
    "Campos R., Mangaravite V., Pasquali A., Jorge A.M., Nunes C., and Jatowt A. (2018). A Text Feature Based Automatic Keyword Extraction Method for Single Documents. In: Pasi G., Piwowarski B., Azzopardi L., Hanbury A. (eds). Advances in Information Retrieval. ECIR 2018 (Grenoble, France. March 26 – 29). Lecture Notes in Computer Science, vol 10772, pp. 684 - 691. [pdf](https://link.springer.com/chapter/10.1007/978-3-319-76941-7_63)\n",
    "\n",
    "Campos R., Mangaravite V., Pasquali A., Jorge A.M., Nunes C., and Jatowt A. (2018). YAKE! Collection-independent Automatic Keyword Extractor. In: Pasi G., Piwowarski B., Azzopardi L., Hanbury A. (eds). Advances in Information Retrieval. ECIR 2018 (Grenoble, France. March 26 – 29). Lecture Notes in Computer Science, vol 10772, pp. 806 - 810. [pdf](https://link.springer.com/chapter/10.1007/978-3-319-76941-7_80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "251px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
